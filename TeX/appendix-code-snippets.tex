\chapter{Extended Code References}
\label{chap:code}


\section{AeroSandbox Benchmark on Beam Static Structural Analysis}

This Python code is used for the AeroSandbox performance benchmark used in Section \ref{sec:benchmark_gpkit}, with associated runtimes shown as the line labeled ``AeroSandbox'' in Figure \ref{fig:benchmark_gp_beam}. In this analysis problem, a cantilever beam is subject to a distributed load, and the goal is to compute the state of the deflected beam. The code is shown in Listing \ref{lst:gpkit_beam}.

\begin{listing}[h]
    \begin{minted}{python}
import aerosandbox as asb
import aerosandbox.numpy as np

N = 50  # Number of discretization nodes
L = 6  # Overall length of the beam [m]
EI = 1.1e4  # Bending stiffness [N*m^2]
q = 110 * np.ones(N)  # Distributed load [N/m]

x = np.linspace(0, L, N)  # Node locations along beam length [m]

opti = asb.Opti()  # Initialize an optimization environment

w = opti.variable(init_guess=np.zeros(N))  # Displacement [m]

th = opti.derivative_of(  # Slope [rad]
    w, with_respect_to=x,
    derivative_init_guess=np.zeros(N),
)

M = opti.derivative_of(  # Moment [N*m]
    th * EI, with_respect_to=x,
    derivative_init_guess=np.zeros(N),
)

V = opti.derivative_of(  # Shear force [N]
    M, with_respect_to=x,
    derivative_init_guess=np.zeros(N),
)

opti.constrain_derivative(  # Shear integration
    variable=V, with_respect_to=x,
    derivative=q,
)

opti.subject_to([  # Boundary conditions
    w[0] == 0,
    th[0] == 0,
    M[-1] == 0,
    V[-1] == 0,
])

sol = opti.solve()

print(sol(w[-1]))  # Prints the tip deflection; should be 1.62 m.
    \end{minted}
    \caption{AeroSandbox code for a static structural analysis of a beam. Written in Python.}
    \label{lst:gpkit_beam}
\end{listing}


\section{Efficient Computational Implementation of an Arbitrary-Order Noise Estimator}
\label{sec:estimator_code_example}

While the given equation for an arbitrary-order data-driven noise estimator (Equation \ref{eq:arbitrary_order_noise_estimator}) is mathematically correct, it is nontrivial to computationally implement. This is because an implementation as-written involves combinatorial coefficients that grow exponentially with the order of the estimator, quickly exceeding standard double-precision floating-point overflow. A naive implementation also has a runtime complexity that scales linearly with both with the number of samples in the dataset and the order of the estimator, making it computationally unattractive for large datasets or high-order estimators.

An efficient computational implementation of the arbitrary-order noise estimator is given below. This example is based on syntax for NumPy 1.24.3 and SciPy 1.11.1 within Python 3. This implementation uses the log-gamma function, which is much faster for high-order estimators and delays numerical overflow until much higher orders. The implementation also uses a convolutional kernel to vectorize the summation, enabling further speedups.

\begin{listing}[H]
    \begin{minted}[mathescape=true]{python}
import numpy as np
from scipy.special import gammaln

ln_factorial = lambda x: gammaln(x + 1)  # Gives the function $f(x) = \ln(x!)$

def estimate_noise_standard_deviation(
        data: np.ndarray,
        estimator_order: int = 10
    ) -> float:
    """
    Estimates the standard deviation of noise in a time-series data set.
    Assumes stationarity of noise, and that the noise is white (i.i.d.).

    Args:
        data: A 1D NumPy array of time-series data, assumed to consist of signal + noise.
        estimator_order: The order of the estimator to use. A positive integer.

    Returns: The estimated standard deviation of the noise in the data.
    """
    # For speed, cache $\ln(x!)$ for $x \in [$0, estimator_order$]$
    ln_f = ln_factorial(np.arange(estimator_order + 1))

    # Create a convolutional kernel to vectorize the summation
    coefficients = np.exp(
        2 * ln_f[estimator_order] - ln_f - ln_f[::-1] - 0.5 * ln_factorial(2 * estimator_order)
    ) * (-1) ** np.arange(estimator_order + 1)

    # Remove any bias introduced by floating-point error
    coefficients -= np.mean(coefficients)

    # Convolve the data with the kernel
    sample_stdev = np.convolve(data, coefficients[::-1], 'valid')

    # Return the standard deviation of the result
    return np.mean(sample_stdev ** 2) ** 0.5
    \end{minted}
    \caption{Example efficient implementation of the arbitrary-order noise estimator using NumPy/SciPy in Python 3.}
    \label{lst:efficient_arbitrary_order_noise_estimator}
\end{listing}
